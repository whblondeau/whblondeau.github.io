<html>
<head>
    <title>Bill Blondeau, Python Developer and Information Mechanic</title>
    <link rel='stylesheet' type='text/css' href='../css/common.css'/>
</head>
<body>
<div class='wrapper'>
        <p>
        <a href='../index.htm'>home</a>
        </p>
        <p class='instruct'>If your workflow requires a copy of this r&#x00E9;sum&#x00E9;, the simplest way is to copy everything below the line and paste it into a word processing document. If you would prefer that I generate one for you, email me at <a href='mailto:whblondeau@gmail.com'>whblondeau@gmail.com</a>. I'll happily and promptly send it.</p>
        <hr/>
        <h1>Bill Blondeau R&#x00E9;sum&#x00E9;: Python Developer &amp; Information Mechanic</h1>
        <div class='contact-info'>
            <p>122 N. 6th St.</p>
            <p>Madison, WI 53704</p>
            <p><a href='mailto:whblondeau@gmail.com'>whblondeau@gmail.com</a></p>
            <p>References upon request.</p>
        </div>

        <p>
        <em>Note: <strong>this is a blue-sky optimistic r&#x00E9;sum&#x00E9;. It's specifically targeted towards the SIPS Programmer position, which seems remarkably like a dream job.</strong></em>
        </p>
        <p>
        Developer, strong preference for Python, strong preference for the back end. Data Mechanic. Information Architect. Technical Writer.
        </p>
        <p>
        Twenty years of professional and entrepreneurial experience.
        </p>

        <h2>Preface: experience &amp; skills relevant to SIPS Programmer Position at SSEC</h2>
        <p class='explanation'>As a convenience, to save anyone from having to dig through my perhaps excessively distributed documentation: here's an overview of my matches for the stated position requirements.</p>
        <h3>Required:</h3>
        <ul>
            <li><strong>Experience developing and maintaining software systems in Python</strong>
                <p>
                Yes.
                </p>
                <p>
                I reviewed my <a href='http://billblondeau.com/project_hist/software_project_history.htm'>project history</a> and found eighteen projects that used Python. Some of these were large, some small. Some were purely, or primarily, Python; others included Python as one of several languages. I've used Python for other work that didn't make the cut to get into my history. Python has been my go-to for ten or twelve years now.
                </p>
                <p>
                For what it's worth, I've developed a strong preference in Python for the pure functional style, when I can use it. I'm also comfortable with OO and with structured scripting (although the functional style emerges in any nontrivial scripts I write.)
                </p>
            </li>
            <li><strong>Familiarity with the Linux programming environment, including knowledge of operating system concepts and command-line / scripting proficiency</strong>
                <p>
                Yes.
                </p>
                <p>
                I have used Linux personally since 2002. At work I have used Linux and, occasionally, workalikes (MacOSX on one laptop, and Cygwin so I could get serious work done on mandated Windows) since 2004, with very few, very brief lapses. And by Linux I mean the CLI.
                </p>
                <p>
                I'm familiar with the ordinary commands, and frequently use things like <code>tar</code>, <code>curl</code>, <code>tee</code>, <code>ssh</code>, <code>scp</code> and <code>rsync</code>. Most of my system admin work has been with <code>top</code>, <code>ps</code>, <code>systemd</code>, and <code>systemctl</code>. Things I'd like to learn: I consider my experience with <code>screen</code> and <code>xargs</code> to be insufficient, and know little about <code>sed</code> or <code>awk</code>.
                </p>
                <p>
                Also, not to start any quarrels but just to be honest: <code>vim</code> not <code>emacs</code>.
                </p>
                <p>
                When it comes to scripting, I am reasonably capable with <code>bash</code>, but normally I use Python.
                </p>
                <p>
                My favorite distro is Debian; I've also used (or am still using) Fedora, Red Hat, OpenSUSE, and Ubuntu.
                </p>
            </li>
            <li><strong>SQL database programming experience with a DBMS, preferably PostgreSQL</strong>
                <p>
                Yes.
                </p>
                <p>
                This is another strong one. I have used SQL and DDL since 1997. SQL was the first serious language I ever learned, and it's like riding a bicycle&mdash;I've never forgotten it.
                </p>
                <p>
                I use Postgres by preference. My current job uses MySQL. I have used Oracle, DB2, MS SQL Server, and Sybase on major projects.
                </p>
                <p>
                I can design effective, resilient data schemas. I can implement them in DDL for the platform of choice. I can write efficient queries in SQL, and process them efficiently in code. I can troubleshoot long-running queries or peculiar results. I do understand indexing, and I can deal easily with complicated joins (full or outer).
                </p>
                <p>
                I have done a fair amount of ETL, although I always had to roll my own. I have not used the industry standard ETL tools; I would like to learn them, but I'm very comfortable with continuing to write ad hoc, situationally optimized ETL processes.
                </p>
                <p>
                I am not a DBA. But I am a very effective SQL developer.
                </p>
            </li>
            <li><strong>A solid foundation in software engineering practices including use of version control (git), software testing, and creation and maintenance of developer documentation and user manuals</strong>
                <p>
                Yes.
                </p>
                <p>
                <strong>About git,</strong> I can say that in my current job the workflow has me routinely using <code>rebase</code> and <code>branch --set-upstream-to</code>; and occasionally <code>cherry-pick</code> to fix the signal-to-noise ratio when I've unwisely used <code>fetch</code> and <code>pull</code>. <code>git log</code> is my particular friend.
                </p>
                <p>
                As regards <strong>software testing,</strong> I've done less unit testing than I'd like, mainly because 1) some workplaces don't want to spend time on tests, and 2) I haven't been authorized to do as much pure functional programming as I'd like, and I'm That Guy who, when out drinking with coworkers, generously educates the entire bar about how "There is no algebra of state." Unit tests on pure (stateless)functions are compellingly powerful, because you can reason formally about the results. 
                </p>
                <p>
                I have, however, been able to talk my way into writing behavioral or definitional tests using the Gherkin language. (In Python, that's the test framework called "Lettuce"; possibly others by now.) This is, in my experience, very valuable. It connects explicit tests of outcomes to specific inputs and conditions, using human-readable syntax.
                </p>
                <p>
                When it comes to <strong>technical documentation:</strong> I was a technical writer before I was a programmer. And I still do it.
                </p>
                <p>
                My portfolio of written work is <a href='http://billblondeau.com/techwriter/writing_portfolio.htm'>here</a>. I also have a pair of articles about technical writing practices: <a href='http://billblondeau.com/techwriter/good_technical_writing.htm'>What makes for good technical writing?</a> and <a href='http://billblondeau.com/techwriter/analytical_writing.html'>Practical Analytical Writing</a>. They may be useful (or at least interesting).
                </p>
            </li>
            <li><strong>Scientific programming and data visualization experience using tools like the Python / NumPy / Matplotlib ecosystem or alternatives like R or MATLAB</strong>
                <p>
                No.
                </p>
                <p>
                (I'll bet you thought I would say Yes to all of the required experience and abilities, but honesty is critical here.)
                </p>
                <p>
                This would be my longest learning curve out of all of the Required competences. I like this sort of thing as a discipline: when your majors include Physics and Art, you're bound to do a lot of visualization of data and models, if only in your head; but I haven't, at time of writing, used any of these tools.
                </p>
                <p>
                I'd love to learn them, but honestly we have to count this&mdash;strictly interpreted as prior experience&mdash;as a No.
                </p>
            </li>
        </ul>
        <h3>Preferred:</h3>
        <ul>
            <li><strong>A background in cluster computing using batch systems like HTCondor and distributed file systems like Ceph</strong>
                <p>
                No.
                </p>
                <p>
                None of them. Intrigued, though.
                </p>
            </li>
            <li><strong>Experience with message-oriented systems built with RabbitMQ or similar technologies</strong>
                <p>
                A definite Yes.
                </p>
                <p>
                When working at the State Consolidated Court Automation Program in 2003-2005, I was tasked with extending and maintaining their messaging system. It was completely queue-based&mdash;in fact, it may have been the first working implementation of the <a href='https://en.wikipedia.org/wiki/Java_Message_Service'>JMS</a> specification on the planet&mdash;and I was deeply impressed by how startlingly effective and bulletproof it was. I grokked queue architectures quickly, and embarked on a career-long crusade in favor of queues everywhere.
                </p>
                <p>
                I've written lightweight queueing systems in Python. I was aware of RabbitMQ, but I wanted to do the work as an exercise in maximal effective austerity. Also, I have a soft spot for 80% solutions.
                </p>
            </li>
            <li><strong>Front- and back- end web application development skills including client-side programming in Javascript</strong>
                <p>
                Um... it's complicated...
                </p>
                <p>
                I know HTML, HTML5, XHTML. I know the DOM very well.
                </p>
                <p>
                I'm good with CSS. I wrote <a href='http://billblondeau.com//project_hist/software_project_history.htm#slam'>SLAM, a formatting language that compiled to HTML+CSS</a>, to make writing of numerous user-facing forms tractable. And in my current job I do fix some awkward, nontrivial CSS3 bug tickets.
                </p>
                <p>
                I know JavaScript as a language, pretty well. I'm happy to write NodeJS code, for example. (Although, when you've got Python for the back end, NodeJS seems kind of beside the point.)
                </p>
                <p>
                But my emphatic preference is for the back end. That's my strength and my zone. I am deeply reluctant to do front-end work. To be honest, I dislike the contemporary wads-of-JavaScript paradigm of web development, and don't want to go down that road.
                </p>
            </li>
        </ul>
        <p>
        I hope this section is useful. If nothing else, it should save any SIPS reader or evaluator some time.
        </p>
        <p>
        The main body of the r&#x00E9;sum&#x00E9; follows.
        </p>

        <h2>Kinds of work I do</h2>
        <p class='explanation'>Things I'm particularly good with, or interested in.</p>
        <ul>
            <li>Back-end work in Python, bash</li>
            <li>Relational databases / SQL / DDL</li>
            <li>Data Management and Governance</li>
            <li>DevOps work (see <a href='http://billblondeau.com#devops_description'>these remarks</a>)
            <li>All things XML or JSON</li>
            <li>Web Development</li>
            <li>Web Service design, including</li>
            <ul>
                <li>Microservices architecture</li>
                <li>Rest/Hypermedia APIs</li>
            </ul>
            <li>Technical writing / Documentation (portfolio <a href='../techwriter/writing_portfolio.htm' target='_blank'>here</a> if you're interested)</li>
            <li>Information Design</li>
        </ul>

        <h2>Languages</h2>
        <ul>
            <li>Python</li>
            <li>SQL and DDL</li>
            <li>bash</li>
            <li>XML and its domain languages (Xpath, XSLT, XQuery, XML Schema)</li>
            <li>Java</li>
            <li>HTML5 / XHTML / CSS3 / SASS</li>
            <li>JavaScript (strong preference for the back end)</li>
        </ul>

        <h2>Development Tools</h2>
        <p class='explanation'>I use others, and have seldom had a difficult time learning any needed tool. These are the ones I know well, right now.</p>
        <ul>
            <li>Unix / Linux command line</li>
            <li>Git version control &amp; GitHub</li>
            <li>vim</li>
            <li>Sublime Text</li>
            <li>VirtualBox</li>
            <li>NetBeans IDE</li>
        </ul>

        <h2>Infrastructure Tools</h2>
        <ul>
            <li>Jenkins Automation Server</li>
            <li>Ansible</li>
            <li>Nagios system/network monitor</li>
        </ul>


        <h2>Frameworks, servers, libraries, and utilities</h2>
        <p class='explanation'>Some of the most useful and/or interesting things I'm familiar with.</p>
        <ul>
            <li>Flask</li>
            <li>Cucumber and Lettuce BDD frameworks</li>
            <li>Apache Tomcat</li>
            <li>Apache Cocoon</li>
        </ul>

        <h2>Project History</h2>
        <p>
        My software project history is separately published because it's long and detailed: <a href='../project_hist/software_project_history.htm' target='_blank'>http://billblondeau.com/project_hist/software_project_history.htm</a> 
        </p>
        <p>
        I have appended a few entries from the project history to this r&#x00E9;sum&#x00E9; in case such a thing is convenient.
        </p>

        <h2>Employment History</h2>
        <ul>
            <li><a href='https://webcourseworks.com/' target='_blank'>Web Courseworks</a>: December 2017 &mdash; present</li> 
           <li><a href='http://www.musicat.co/the-rabble/' target='_blank'>Rabble</a>: May 2016 &mdash; November 2017</li>
            <li>Anchor and <a href='https://www.oldnational.com/' target='_blank'>Old National</a> Banks: December 2015 &mdash; May 2016</li>
            <li>Freelance Technical and Fiction Writer: April 2015 &mdash; November 2015</li>
            <li><a href='http://cida.usgs.gov/' target='_blank'>US Geological Survey, Center for Integrated Data Analytics</a>: Feb 2013 &mdash; April 2015</li>
            <li><a href='http://bendyworks.com' target='_blank'>Bendyworks Inc</a>: June 2012 &mdash; Dec 2012</li>
            <li><a href='http://beacontechinc.com' target='_blank'>Beacon Technologies Inc</a>: September 2000 &mdash; March 2012</li>
            <li>Keane Inc (now a subsidiary of <a href='http://americas.nttdata.com/Services/Services.aspx' target='_blank'>NTT DATA</a>): May 2000 &mdash; August 2000</li>
            <li><a href='http://www.capgemini.com/' target='_blank'>Cap Gemini Inc</a>: June 1999 &mdash; May 2000</li>
            <li>InterMedia LLC (now <a href='http://www.infinitecampus.com/' target='_blank'>Infinite Campus</a>): May 1997 &mdash; May 1999</li>
        </ul>

        
        
        <a name='education'></a>
        <h2>Education</h2>
        <p>
        Attended UW-Oshkosh part time from 1982 &mdash; 1988. Multiple major (Physics, History, and Art) with minors in Math and German. Earned 140 credits with a cumulative GPA of 3.45. Those credits, given the diversity of the majors and minors, did not add up to any degree.
        </p>
        <p>
        I left school for non-academic reasons. I still feel it was extraordinary worthwhile. I learned how to think effectively in multiple intellectual and creative modes. I learned how to learn.
        </p>
        <p>
        I enjoy describing myself as an Art School Dropout.
        </p>

        
        <a name='project_history_extract'></a>
        <h2>Excerpts from Project History</h2>
        <p class='explanation'>My project history is large and unwieldy for direct inclusion in a r&#x00E9;sum&#x00E9; (and this r&#x00E9;sum&#x00E9; is in my opinion far too long already).</p>
        <p class='explanation'>But in case the evaluation workflow requires printed sheets of paper, I have cherry-picked a few representative, recent items. Please feel free to look at the project history at <a href='http://billblondeau.com/project_hist/software_project_history.htm' target='_blank'>http://billblondeau.com/project_hist/software_project_history.htm</a> for the full story.</p>

        <a name='webcourseworks'></a>
        <h3>Web Courseworks: <code>DevOps</code> Software deployment to Staging  &mdash; January 2018 to present</h3>
        <p class='role'>DevOps</p>
        <p>
        Web Courseworks maintains numerous GitHub repositories for several products. These all need to have new features and bugfixes applied; also, changes to the more general feature repositories need to be propagated to customized repos. Changes must then be pushed to the corresponding Staging servers for testing.
        </p>
        <p>
        Code merges involve GitHub Pull Requests, scripted git commands, and manual sequences of git commands. This is followed by deployment to various hosting services, including Amazon Web Services. Pre-deploy database backups are often required. Often, several merge/push operations occur simultaneously.
        </p>
        <p>
        I've done the majority of these operations for Web Courseworks for over a year. To keep this critical sequence of operations in order, keep things from falling through the cracks, and provide summary reports of actions taken, I wrote several Python utilities, which have proven to be indispensable.
        </p>
        <p class='tools'>git, GitHub, ssh, Ansible, MySQL, AWS, Python, vim</p>

        <a name='marcout'></a>
        <h3>MARCout bibliographic export (November 2017 to January 2018)</h3>
        <p class='role'>Designer, Developer</p>
        <p>
        The <a href='http://www.loc.gov/marc/bibliographic/'>MARC 21 format</a> is a bibliographic data representation standard published by the Library of Congress. Despite its difficult aspects (it's old, it goes back to times when information was expensive to store and represent, and its implementations are often inconsistently complete&mdash;the joke goes, "MARC is already here, it's just not evenly distributed yet"), MARC 21 is deeply embedded in library information systems everywhere.
        </p>
        <p>
        This project was requested by Rabble as a more robust means of providing MARC21 bibliographic exports of Rabble customers' MUSICat music catalogs. The primary purpose was for the customers to extract bibliographic information from their MUSICat instance, and import it into their own main library catalogs. Important additional uses include the ability to provision shared catalogs.
        </p>
        <p>
        Since the customers wanted various combinations and sequences of MARC elements in their import records, using various serializations&mdash;MARC, like many well-established open standards, breeds idiosyncratic patterns of usage&mdash;Rabble and I settled on a three-part design:
        </p>
        <ul>
            <li>A reasonably human-friendly Domain-Specific Language, called "MARCout", that bibliographers could use for specifying desired sequences of MARC elements and the transforms to be applied to the content.</li>
            <li>A MARCout component that would:
                <ul> 
                    <li>parse a MARCout document;</li>
                    <li>self-configure from the parsed MARCout;</li>
                    <li>convert an output record to the stipulated MARC datastructure;</li>
                    <li>serialize the MARC output in several formats (including the mildly notorious <a href='https://en.wikipedia.org/wiki/ISO_2709'>ISO 2709</a> byte-oriented format);</li>
                </ul>
            </li>
            <li>A Web Service wrapper that would isolate MUSICat from the implementation details of the MARCout component.</li>
        </ul>
        <p>
        The component was implemented in Python (nothing else would have been expressive and comprehensible enough for my short deadline). The Webservice was written in Flask. I also wrote&mdash;directly into Rabble's codebase&mdash;the NodeJS client code with which they could call the Web Service and export the result.
        </p>
        <p>
        The project turned out to be highly successful (especially for a rush job in off hours), allowing Rabble to affordably provide the desired customizable MARC21 exports to customers with varying MARC21 composition, format, and serialization requirements.
        </p>
        <p>
        Now if I can just get a couple of the Rabble devs to send me some pull requests for fixes and enhancements they've implemented...
        </p>
        <p>
        This project is at <a href='https://github.com/whblondeau/marcout' target='_blank'>https://github.com/whblondeau/marcout</a>. It includes <a href='https://github.com/whblondeau/marcout/blob/master/examples/export_define.marcout'>an example MARCout file</a>.
        </p>
        <p class='tools'>Python, Flask, linux CLI, git, NodeJS for client code</p>


        <a name='jnpath'></a>
        <h3>Independent project <code>JNPath</code> (ongoing since June 2017)</h3>
        <p class='role'>Language Designer, Developer</p>
        <p>
        I'm highly proficient with the XPath languages and tools for XML. While working with JSON data for Rabble's MUSICat, I became increasingly dissatisfied with the lack of a comparably useful set of declarative capabilities for JSON. JNPath is a pragmatic attempt to provide a considered, limited set of such capabilities. Its pattern-matching expression language avoids the syntax of the XML world, concentrating on familiar JSON notation conventions. Expressions are also designed for cognitive accessibility.
        </p>
        <p>
        JNPath will provide a specification, a reference implementation in Python, a set of derived command line utililties, and a convenience implementation in JavaScript.
        </p>
        <p>
        This project is at <a href='https://github.com/whblondeau/jnpath' target='_blank'>https://github.com/whblondeau/jnpath</a>.
        </p>
        <p class='tools'>JSON, Python, linux CLI, git, JavaScript</p>

        
        <a name='rabble-musicat'></a>
        <h3>Rabble: <code>MUSICat</code> local music curation for public libraries  &mdash; May 2016 to November 2017</h3>
        <p class='role'>Developer, Devops, Data Mechanic</p>
        <p>
        MUSICat is a hosted web app for managing collections of music. It's explicitly designed and built for public libraries. It provides essential capabilities: 
        </p>
        <ul>
            <li>Initial solicitation of music submissions</li>
            <li>Juried selection/curation of submissions</li>
            <li>Honoraria for selected works</li>
            <li>Signed contracts for publication</li>
            <li>Publication of collected music, for streaming and downloads</li>
            <li>Personal playlists for individual library patrons</li>
        </ul>
        <p>
        MUSICat is a single page web app. The front end is implemented in Ember JS and Node JS; the back end is NodeJS and Redis, hosted on a Google Compute Engine Debian server.
        </p>
        <p>
        Examples of live MUSICat sites:
        </p>
        <ul>
            <li><a href='https://capitalcityrecords.ca/' target='_blank'>Capital City Records</a>, Edmonton Public Library</li>
            <li><a href='https://playback.spl.org/' target='_blank'>Seattle PlayBack</a>, Seattle Public Library</li>
            <li><a href='https://boombox.library.nashville.org/' target='_blank'>Nashville BoomBox</a>, Nashville Public Library</li>
            <li><a href='https://yaharamusic.org/' target='_blank'>Yahara Music Library</a>, Madison Public Library</li>
        </ul>
        <p class='tools'>JavaScript, Python, NodeJS, Redis DB, EmberJS, JSON, Google Compute Engine, Debian, linux CLI, git</p>

        <a name='nautilus_admin'></a>
        <h3>Anchor Bank / Old National Bank: Nautilus administration and automation &mdash; December 2015 to May 2016</h3>
        <p class='role'>System Administrator, Documentation specialist, Programmer</p>
        <p>
        Anchor Bank's <a href='https://www.fiserv.com/insights-optimization/enterprise-content-management/nautilus.aspx' target='_blank'>Nautilus</a> document image management system was being administered by a set of manual tasks guided by institutional knowledge that had been lost. Documentation was insufficient. My task was to upgrade the outdated Nautilus system, catch up with elapsed maintenance, properly document the procedures for maintenance, and automate any recurring work that I could. Much of the work involved harvesting information from Nautilus's formatted text reports. Automation was done with Python.
        </p>
        <p>
        Shortly after I came aboard, Old National Bank bought Anchor Bank out. This increased the urgency of knowledge capture and automation, due to anticipated losses of key personnel during the transition period.
        </p>
        <p>
        This project (if such it could be called) was effective and successful. By the time I myself departed, the necessary aspects of the Nautilus system had been documented, automated, and stabilized.
        </p>
        <p class='tools'>Python, Nautilus admin console, Cygwin CLI, Windows Active Directory</p>

        <a name='usgs_ngwmn_mediation_refactor'></a>
        <h3>USGS/CIDA: Refactor of NGWMN Mediation &mdash; January to March 2015</h3>
        <p class='role'>Researcher, Developer</p>
        <p>
        The <a href='http://cida.usgs.gov/ngwmn/' target='_blank'>National Groundwater Monitoring Network</a> (NGWMN), a portal for shared groundwater quality data from disparate sources, had been running in limited prototype mode for several years. In anticipation of a major increase in the number of participating agencies, I refactored NGWMN's information topology for <em>Mediation</em>, the term of art for accepting information from multiple contributors in arbitrary formats, and converting it to the NGWMN's standard internal data representation.
        </p>
        <p>
        As a necessary part of that, I developed a heavyweight regression test, exercised it, and delivered it with thorough documentation. (You can see a summary documentation excerpt <a href='../portfolio/ngwmn/exercising_and_testing.html#howto_do_regression_test' target='_blank'>here</a>.)
        </p>
        <p class='tools'>Apache Cocoon, Python, XML/XSLT, Oxygen XML Editor</p>


        <a name='usgs_nagios'></a>
        <h3>USGS/CIDA: Internal monitoring using NAGIOS &mdash; November 2014 to January 2015</h3>
        <p class='role'>Researcher, Developer</p>
        <p>
        CIDA was evaluating <a href='https://en.wikipedia.org/wiki/Nagios' target='_blank'>NAGIOS</a>, an open source framework for monitoring server, network, and application assets. I wrote a <a href='https://github.com/wblondeau-usgs/tomcat-monitor' target='_blank'>prototype client in Python</a> that would invoke the built-in self-reporting capabilities of <a href='http://tomcat.apache.org/tomcat-7.0-doc/manager-howto.html' target='_blank'>Tomcat Manager</a> included by default in each installation of the Apache Tomcat HTTP Server.
        </p>
        <p class='tools'>NAGIOS, Python, Python Requests, Python Beautiful Soup, Tomcat HTTP Server, Tomcat Manager, REST, bash scripting</p>


        <a name='usgs_pubs_warehouse_bdd'></a>
        <h3>USGS/CIDA: USGS Pubs Warehouse behavioral testing &mdash; October &amp; November 2014</h3>
        <p class='role'>Developer</p>
        <p>
        The <a href='http://pubs.er.usgs.gov/' target='_blank'>USGS Publications Warehouse</a> provides online access to the very large, and continually increasing, store of official USGS publications. Internal document management was being implemented using JSON notation for semantics. I was tasked with writing Behavioral Tests in Gherkin to ensure that the mechanism for documents to supersede previous versions was correct.
        </p>
        <p class='tools'>Python, JSON, Lettuce BDD framework, Gherkin</p>

        <a name='usgs_pywqp'></a>
        <h3>USGS/CIDA: pywqp Water Quality Dataset Client &mdash; June to September 2014</h3>
        <p class='role'>Developer</p>
        <p>
        The <a href='http://waterqualitydata.us' target='_blank'>Water Quality Data Portal</a>, built and operated by CIDA, offers a web client for download of large datasets. This project created a complementary scriptable Python client to accomplish the same task. See <a href='https://github.com/wblondeau-usgs/pywqp' target='_blank'>the pywqp GitHub repository</a> for code, documentation, and details.
        </p>
        <p class='tools'>Python, Python-Requests, REST, Lettuce BDD framework, Gherkin</p>

    </div>
</body>
</html>
